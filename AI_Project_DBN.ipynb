{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Belief Network (DBN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "w3jn9fjfsMCh"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics._classification import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import get_file\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXHEAIGh4Upg",
    "outputId": "77fd2c2c-afbc-430e-afcc-f3f0fd455a52"
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/drive/')\n",
    "PROJECT_PATH = 'C:/Users/coast/Documents/UTSA Documents/Artificial Inteligence/Project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cO66AcSylrYN",
    "outputId": "a68202ce-9177-40a3-b3ee-eca268a8a8be"
   },
   "outputs": [],
   "source": [
    "# Another import statement to use the dbn classes.\n",
    "sys.path.append(PROJECT_PATH)\n",
    "from dbn.tensorflow import SupervisedDBNClassification \n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "#csv to dataframe conversion \n",
    "path = get_file('kddcup.data_10_percent.gz', origin='http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz')\n",
    "df = pd.read_csv(path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EAbBFdP06NxU"
   },
   "outputs": [],
   "source": [
    "df.columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'outcome'\n",
    "]\n",
    "\n",
    "fin = []\n",
    "\n",
    "for i in range(1,4):\n",
    "    v = set(df.iloc[:,i].values)\n",
    "    fin += v     \n",
    "    \n",
    "d = dict(enumerate(fin, start=1))\n",
    "mymap = dict((v,k) for k,v in d.items())\n",
    "\n",
    "#making string to numbers\n",
    "dataset = df.applymap(lambda s: mymap.get(s) if s in mymap else s)\n",
    "\n",
    "#selecting the columns excluding lables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "\n",
    "#selecting the lables column \n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "#scaling by doing normalisation\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-VtLbNK8C63",
    "outputId": "a8fbdfe8-0af5-45cf-bb4c-78906eaff5ec",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Pre-training step:\n"
     ]
    }
   ],
   "source": [
    "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256], learning_rate=0.05, n_epochs_rbm=10)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbklsvZKzsOT"
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print('Accuracy of prediction: %.3f' % accuracy_score(X_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AI_Project_DBN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
